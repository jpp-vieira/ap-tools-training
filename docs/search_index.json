[["index.html", "RAP Manual 1 Intro to statistics publication RAP", " RAP Manual MoJ RAP Manual Working Group 2021-08-11 1 Intro to statistics publication RAP RAP stands for “Reproducible Analytical Pipeline”. Reproducible: Meaning that at any point in the future we should be able to look back at this work and be able to reproduce everything that we have done today. No more getting queries about a publication from five years ago and searching around to try to find how a figure was calculated. Pipeline: Meaning an end-to-end system that is as close as possible as a ‘one click’ process for turning source data into useful analytical outputs. These should ideally be produced to be ‘future-proof’ or easily maintainable to take account of new developments (eg. package updates/data changes) There are a range of different approaches to RAP. Within MoJ, we would like to prioritise the production of harmonised, understandable data files as a primary RAP output, from which additional outputs, such as publication text, charts and tables can be built along with other uses of the data, such as data visualisations. This guide applies principally to the development of RAP processes for the production of statistical publications. The diagram below illustrates how a full analytical pipeline might look at a high level: "],["rap-struc.html", "2 RAP Structure 2.1 Use one repo for each endpoint in your process 2.2 Common structure to a RAP repo", " 2 RAP Structure In order to develop a pipeline like the one above, certain ways of structuring your RAP project can help. 2.1 Use one repo for each endpoint in your process As in the diagram above, define a set of endpoints or outputs that your process will produce. This could include: Cleaned datasets for internal use Publishable datasets (these may be the same as those above) Publication outputs (Charts, Tables, Publication text) Separate repos for other outputs (eg. MI packs, briefing packs, data visualisation tools) This makes it easier to use outputs for multiple purposes, rather than having to extract them from the middle of a larger process. It also allows other users who want to adapt your code or outputs to find the section of code that they need, without having to understand the full range of code. In the diagram above, the aim of the first repository should be to render the data into a format that can be used to produce the broadest range of other outputs, which are then each created within their own repositories. You should also consider the point at which you want to include disclosure control in the process. For example, the first repo might create a full, unredacted dataset for internal use. You may they want to include a further stage which aggregates data to prevent small numbers being generated. 2.2 Common structure to a RAP repo A RAP repository should have: An ‘inputs’ folder, for any inputs required by the process. This should only be used for things like lookup tables, templates etc. Datasets should be stored in s3. An ‘outputs’ folder, for all outputs (eg. HTML, pdf, png) generated by the process. A ‘processing’ folder containing R scripts or Rmd files used in the process. A ‘functions’ folder within the processing folder, containing any functions created for the process. A RAP repository should not have: Stored datasets General functions. These should be stored in a package – ideally mojrap, or a process-specific package if necessary. Note that this structure only applies to a RAP repo that works as a series of scripts run manually. You may wish to create your repo as a package, in which case you should adopt the required structure for a package. "],["git-flow.html", "3 Version Control with Git Flow", " 3 Version Control with Git Flow Git Flow is an ideal workflow for Git and GitHub to allow collaboration and development of new features. It is based on three types of branch: Master – the live version of the code, managed by an administrator. No editing is done on this branch. Development – a staging area for testing finished features together, before getting merged into the live master branch Features – these branches are used for individual new features. When a new feature is worked on, before testing it with other new features it gets developed on its own branch, which can be collaborated on by multiple people. When a feature is finished and had unit testing completed, it can be merged into the development branch. This will also feed in to the categorisation of a release within GitHub. Within RAP, each release should align with a finalised process for the production of a single publication. This means that in future we can easily revert code to its state at the point of publication and easily recreate old data if needed. For more information, see Learn to love Github with Git Flow. "],["data-struc.html", "4 Data Structures", " 4 Data Structures When developing RAP processes, you should ensure that your data adheres to tidy data formats at each stage. At its core this means adhering to three basic principles: Each variable must have its own column Each observation must have its own row Each value must have its own cell In most cases, this will also mean only having one column of values, while every other column is used to define that value. For example, if you were creating a dataset showing the prison population by age over time, it might look like this: Pop_2017 Pop_2018 Pop_2020 15-17 470 3540 70706 18-20 444 3241 68861 21+ 409 3192 69142 This way of arranging a dataset is not tidy because each observation doesn’t have its own row. Each row contains an observation for 2017, 2018 and 2019. To convert this dataset to tidy data, you would rearrange it to the following: Age Year Population 15-17 2017 470 18-20 2017 3540 21+ 2017 70706 15-17 2018 444 18-20 2018 3241 21+ 2018 68861 15-17 2019 409 18-20 2019 3192 21+ 2019 69142 As you can see from the above example, turning your dataset into tidy data can be thought of as making it longer and thinner, with a single column of values. There are three main advantages to following a tidy data structure within RAP: Picking one consistent way of storing data allows you to learn how to use tools and packages within R and apply them across multiple datasets. It also enables you to use and develop functions and packages that will work across multiple datasets because you know how the data will be structured. Commonly used tools like dplyr and ggplot2 are designed to work with tidy data. R is designed to work with vectorised data. Placing variables in columns transforms your data into a set of vectors and so it will be easier to work with within R. For these reasons it is desirable to get your data into tidy format as soon as possible within your RAP process so you can start using some of these advantages as early in the process as possible. Sometimes you may want to output data in an ‘untidy’ format, such as for outputs that are to be looked at by a user but not to be read by further code. Make sure to have these be the final output rather than datasets that are then manipulated by your code. All data wrangling should be done with tidy data. For more information on tidy data, see https://r4ds.had.co.nz/tidy-data.html "],["generalisable-code.html", "5 Generalisable Code", " 5 Generalisable Code When writing code, you should consider how to make it as generalisable as possible. That is, you should write your code in a way that allows yourself and others to take what you’ve written and use it for several different purposes. In practice, this means writing code as functions within R. A function is a set of commands that are bundled together so that they can all be repeated with a single line of code. A function will generally accept different inputs, or parameters, which allows it to be applied in different situations. Within R, functions can be grouped together in packages. This means writing your code as much as possible to use these three methods (in reverse order of preference): Custom functions Custom packages Multi-use packages (eg. mojrap) Code should use as few individual lines of processing as possible. You should design your process to make use of functions as much as possible and these functions should be designed to work on other datasets than those within your RAP process. When creating functions, make them as generalisable as possible. This means not including any code within your function that is only applicable to your data and not hardcoding any dataset-specific variables. Any references to data should be set within the parameters of the function so that the function can work on other datasets. Code that is used to recode variables, for example, should refer to a lookup table rather than hard-coding the recodes within the function. This means that your function can be used in other contexts by simply referring to a new lookup table. These functions should be built into packages, either custom packages for your particular RAP, or packages such as mojrap which work across multiple processes. Mojrap is intended to serve as the repository for functions that can be used across publications within MOJ. It is also good practice to use the common packages used across tidy data to standardise your code, these could include: dplyr tidyverse openxlsx ggplot2 When writing your RAPped code in R, it is good practice to use package names with a double colon when calling functions from external packages. For example, when using dplyr’s filter function use dplyr::filter rather than just filter. This means whenever your code is reproduced, the packages required to run it are obvious from the functions used within the code. This also makes functions easier to code into packages if you do this later down the line. "],["standards.html", "6 Develop your process against a defined set of standards", " 6 Develop your process against a defined set of standards A RAP, standing for Reproducible Analytical Pipeline, is a production methodology for automating the steps involved in creating a statistical report. It is a series of practices that focus on reproducibility –at any point in the future we should be able to look back at this work and be able to reproduce everything that we have done today. There are various ways of measuring how well a RAP project meets these aims. The chart below shows a range of steps along that process, with Stages 4a onwards considered to be ‘RAP’. You may also wish to consider the RAP Minimum Viable Product Within all these methods, there is an emphasis on good coding practices. You should followe the DASD Coding Principles within your project. "]]
